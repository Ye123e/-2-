#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Androidç³»ç»Ÿä¿®å¤å·¥å…·é—ªé€€é—®é¢˜ä¿®å¤ - ç»¼åˆæµ‹è¯•
æµ‹è¯•æ‰€æœ‰é—ªé€€ä¿®å¤ç›¸å…³åŠŸèƒ½
"""

import sys
import os
import unittest
import tempfile
import shutil
import time
import threading
import json
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src.utils.exception_handler import (
        ExceptionHandlingCenter, ExceptionSeverity, RecoveryAction,
        get_exception_center, exception_handler, safe_execute
    )
    from src.utils.intelligent_starter import (
        IntelligentStarter, StartupMode, StartupConfig,
        get_intelligent_starter, smart_start
    )
    from src.utils.auto_repair_manager import (
        AutoRepairManager, ProblemType, RepairStatus, Problem,
        DependencyRepairer, ConfigRepairer, get_auto_repair_manager
    )
    from src.utils.diagnostic_tools import (
        DiagnosticRunner, PythonEnvironmentDiagnostic, 
        SystemResourceDiagnostic, NetworkConnectivityDiagnostic
    )
    from src.utils.logger import (
        ColoredFormatter, JSONFormatter, BufferedFileHandler,
        CrashRecoveryHandler, PerformanceMetricsHandler, setup_logger
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥æµ‹è¯•æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


class TestExceptionHandlingCenter(unittest.TestCase):
    """æµ‹è¯•å¼‚å¸¸å¤„ç†ä¸­å¿ƒ"""
    
    def setUp(self):
        self.center = ExceptionHandlingCenter()
    
    def test_singleton_pattern(self):
        """æµ‹è¯•å•ä¾‹æ¨¡å¼"""
        center1 = get_exception_center()
        center2 = get_exception_center()
        self.assertIs(center1, center2)
    
    def test_exception_registration(self):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†å™¨æ³¨å†Œ"""
        def test_handler(exc):
            return True
        
        self.center.register_handler(ValueError, test_handler)
        
        # æµ‹è¯•å¼‚å¸¸å¤„ç†
        test_exception = ValueError("test error")
        result = self.center.handle_exception(test_exception)
        self.assertTrue(result)
    
    def test_exception_statistics(self):
        """æµ‹è¯•å¼‚å¸¸ç»Ÿè®¡"""
        # æ¨¡æ‹Ÿä¸€äº›å¼‚å¸¸
        exceptions = [
            ValueError("test1"),
            TypeError("test2"), 
            RuntimeError("test3")
        ]
        
        for exc in exceptions:
            self.center.handle_exception(exc)
        
        stats = self.center.get_exception_statistics()
        self.assertEqual(stats["total"], 3)
        self.assertIn("by_type", stats)
    
    def test_exception_decorator(self):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†è£…é¥°å™¨"""
        @exception_handler(severity=ExceptionSeverity.LOW)
        def test_function():
            raise ValueError("test error")
        
        # åº”è¯¥ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        result = test_function()
        self.assertIsNone(result)
    
    def test_safe_execute(self):
        """æµ‹è¯•å®‰å…¨æ‰§è¡Œ"""
        def failing_function():
            raise ValueError("test error")
        
        def working_function():
            return "success"
        
        # æµ‹è¯•å¤±è´¥å‡½æ•°
        result = safe_execute(failing_function, default_return="failed")
        self.assertEqual(result, "failed")
        
        # æµ‹è¯•æˆåŠŸå‡½æ•°
        result = safe_execute(working_function)
        self.assertEqual(result, "success")


class TestIntelligentStarter(unittest.TestCase):
    """æµ‹è¯•æ™ºèƒ½å¯åŠ¨å™¨"""
    
    def setUp(self):
        self.starter = IntelligentStarter()
    
    def test_argument_parsing(self):
        """æµ‹è¯•å‚æ•°è§£æ"""
        # æµ‹è¯•è¯Šæ–­æ¨¡å¼
        config = self.starter.parse_arguments(["--diagnostic", "--verbose"])
        self.assertEqual(config.mode, StartupMode.DIAGNOSTIC)
        self.assertEqual(config.log_level, "DEBUG")
        
        # æµ‹è¯•å®‰å…¨æ¨¡å¼
        config = self.starter.parse_arguments(["--safe", "--minimal-ui"])
        self.assertEqual(config.mode, StartupMode.SAFE)
        self.assertTrue(config.minimal_ui)
    
    def test_startup_phases(self):
        """æµ‹è¯•å¯åŠ¨é˜¶æ®µ"""
        # æ¨¡æ‹ŸæˆåŠŸçš„æ£€æŸ¥
        with patch.object(self.starter, '_execute_phase_check') as mock_check:
            mock_check.return_value = Mock(success=True, message="OK", details={})
            
            result = self.starter._execute_startup_checks()
            self.assertTrue(result)
    
    def test_auto_fix_mechanism(self):
        """æµ‹è¯•è‡ªåŠ¨ä¿®å¤æœºåˆ¶"""
        # åˆ›å»ºä¸€ä¸ªéœ€è¦ä¿®å¤çš„æ£€æŸ¥ç»“æœ
        check_result = Mock()
        check_result.success = False
        check_result.fix_available = True
        check_result.fix_action = Mock(return_value=True)
        
        result = self.starter._attempt_auto_fix(None, check_result)
        self.assertTrue(result)
        check_result.fix_action.assert_called_once()
    
    def test_startup_history(self):
        """æµ‹è¯•å¯åŠ¨å†å²è®°å½•"""
        # è®°å½•ä¸€äº›å¯åŠ¨å†å²
        self.starter._record_startup_history(True, 2.5)
        self.starter._record_startup_history(False, 1.8)
        
        stats = self.starter.get_startup_statistics()
        self.assertEqual(stats["total"], 2)
        self.assertEqual(stats["successful"], 1)
        self.assertEqual(stats["failed"], 1)


class TestAutoRepairManager(unittest.TestCase):
    """æµ‹è¯•è‡ªåŠ¨ä¿®å¤ç®¡ç†å™¨"""
    
    def setUp(self):
        self.manager = AutoRepairManager()
    
    def test_repairer_registration(self):
        """æµ‹è¯•ä¿®å¤å™¨æ³¨å†Œ"""
        repairer = DependencyRepairer()
        self.manager.register_repairer(ProblemType.DEPENDENCY_MISSING, repairer)
        
        # éªŒè¯æ³¨å†Œ
        repairers = self.manager.repairers.get(ProblemType.DEPENDENCY_MISSING, [])
        self.assertIn(repairer, repairers)
    
    def test_repair_plan_creation(self):
        """æµ‹è¯•ä¿®å¤è®¡åˆ’åˆ›å»º"""
        problems = [
            Problem(
                problem_type=ProblemType.CONFIG_INVALID,
                severity=5,
                description="é…ç½®æ–‡ä»¶æŸå",
                auto_fixable=True
            ),
            Problem(
                problem_type=ProblemType.DEPENDENCY_MISSING,
                severity=8,
                description="ç¼ºå°‘ä¾èµ–åŒ…", 
                auto_fixable=True
            )
        ]
        
        repair_plan = self.manager.create_repair_plan(problems)
        self.assertEqual(len(repair_plan), 2)
        
        # éªŒè¯æŒ‰ä¼˜å…ˆçº§æ’åº
        self.assertGreaterEqual(repair_plan[0].problem.severity, repair_plan[1].problem.severity)
    
    def test_dependency_repairer(self):
        """æµ‹è¯•ä¾èµ–ä¿®å¤å™¨"""
        repairer = DependencyRepairer()
        
        problem = Problem(
            problem_type=ProblemType.DEPENDENCY_MISSING,
            severity=5,
            description="ç¼ºå°‘åŒ…",
            details={"missing_packages": ["fake-package-for-test"]}
        )
        
        # æµ‹è¯•æ˜¯å¦å¯ä»¥ä¿®å¤
        self.assertTrue(repairer.can_repair(problem))
        
        # æµ‹è¯•æ—¶é—´ä¼°ç®—
        estimated_time = repairer.estimate_time(problem)
        self.assertGreater(estimated_time, 0)
    
    def test_config_repairer(self):
        """æµ‹è¯•é…ç½®ä¿®å¤å™¨"""
        repairer = ConfigRepairer()
        
        problem = Problem(
            problem_type=ProblemType.CONFIG_INVALID,
            severity=3,
            description="é…ç½®æ— æ•ˆ",
            details={"config_path": "test_config.ini"}
        )
        
        self.assertTrue(repairer.can_repair(problem))
        
        # æµ‹è¯•ä¿®å¤æ‰§è¡Œï¼ˆéœ€è¦æ¨¡æ‹Ÿï¼‰
        with tempfile.NamedTemporaryFile(suffix=".ini", delete=False) as f:
            problem.details["config_path"] = f.name
            
            with patch('src.utils.config_validator.ConfigValidator') as mock_validator:
                mock_config = Mock()
                mock_validator.return_value.create_default_config.return_value = mock_config
                
                result = repairer.execute(problem)
                self.assertTrue(result.get("success", False))
            
            # æ¸…ç†
            os.unlink(f.name)


class TestDiagnosticTools(unittest.TestCase):
    """æµ‹è¯•è¯Šæ–­å·¥å…·"""
    
    def test_python_environment_diagnostic(self):
        """æµ‹è¯•Pythonç¯å¢ƒè¯Šæ–­"""
        diagnostic = PythonEnvironmentDiagnostic()
        result = diagnostic.check()
        
        self.assertIsNotNone(result.checker_name)
        self.assertIn(result.status.value, ["pass", "warning", "fail", "error"])
        self.assertIsInstance(result.details, dict)
        self.assertIn("python_version", result.details)
    
    def test_system_resource_diagnostic(self):
        """æµ‹è¯•ç³»ç»Ÿèµ„æºè¯Šæ–­"""
        diagnostic = SystemResourceDiagnostic()
        result = diagnostic.check()
        
        self.assertIsNotNone(result.message)
        self.assertIsInstance(result.suggestions, list)
    
    def test_diagnostic_runner(self):
        """æµ‹è¯•è¯Šæ–­è¿è¡Œå™¨"""
        runner = DiagnosticRunner()
        
        # æµ‹è¯•è¿è¡Œæ‰€æœ‰è¯Šæ–­
        results = runner.run_all("json")
        
        self.assertIn("diagnostics", results)
        self.assertIn("summary", results)
        
        summary = results["summary"]
        self.assertIn("total", summary)
        self.assertIn("passed", summary)
        self.assertIn("warnings", summary)
        self.assertIn("failed", summary)
    
    def test_standalone_diagnostic(self):
        """æµ‹è¯•ç‹¬ç«‹è¯Šæ–­å·¥å…·"""
        diagnostic = PythonEnvironmentDiagnostic()
        
        # é‡å®šå‘è¾“å‡ºæµ‹è¯•
        import io
        from contextlib import redirect_stdout
        
        f = io.StringIO()
        with redirect_stdout(f):
            output = diagnostic.run_standalone("json")
        
        self.assertIn("checker", output)
        self.assertIn("result", output)


class TestLoggerEnhancements(unittest.TestCase):
    """æµ‹è¯•æ—¥å¿—ç³»ç»Ÿå¢å¼º"""
    
    def test_colored_formatter(self):
        """æµ‹è¯•å½©è‰²æ ¼å¼åŒ–å™¨"""
        formatter = ColoredFormatter()
        
        import logging
        record = logging.LogRecord(
            name="test", level=logging.INFO, pathname="", lineno=1,
            msg="test message", args=(), exc_info=None
        )
        
        formatted = formatter.format(record)
        self.assertIn("test message", formatted)
    
    def test_json_formatter(self):
        """æµ‹è¯•JSONæ ¼å¼åŒ–å™¨"""
        formatter = JSONFormatter()
        
        import logging
        record = logging.LogRecord(
            name="test", level=logging.ERROR, pathname="", lineno=1,
            msg="test error", args=(), exc_info=None
        )
        
        formatted = formatter.format(record)
        data = json.loads(formatted)
        
        self.assertEqual(data["level"], "ERROR")
        self.assertEqual(data["message"], "test error")
        self.assertIn("timestamp", data)
    
    def test_crash_recovery_handler(self):
        """æµ‹è¯•å´©æºƒæ¢å¤å¤„ç†å™¨"""
        recovery_calls = []
        
        def test_recovery_callback(issue):
            recovery_calls.append(issue)
        
        handler = CrashRecoveryHandler(test_recovery_callback)
        
        # æ¨¡æ‹Ÿä¸¥é‡é”™è¯¯
        import logging
        critical_record = logging.LogRecord(
            name="test", level=logging.CRITICAL, pathname="", lineno=1,
            msg="critical error", args=(), exc_info=None
        )
        
        handler.emit(critical_record)
        
        self.assertEqual(handler.critical_count, 1)
        self.assertEqual(len(recovery_calls), 1)
    
    def test_performance_metrics_handler(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡å¤„ç†å™¨"""
        handler = PerformanceMetricsHandler()
        
        import logging
        
        # æ¨¡æ‹Ÿä¸åŒçº§åˆ«çš„æ—¥å¿—
        for level in [logging.INFO, logging.WARNING, logging.ERROR]:
            record = logging.LogRecord(
                name="test", level=level, pathname="", lineno=1,
                msg="test message", args=(), exc_info=None
            )
            handler.emit(record)
        
        stats = handler.get_performance_stats()
        self.assertIn("log_count_by_level", stats)
        self.assertIn("uptime", stats)
        
        # æ£€æŸ¥çº§åˆ«ç»Ÿè®¡
        level_counts = stats["log_count_by_level"]
        self.assertEqual(level_counts.get("INFO", 0), 1)
        self.assertEqual(level_counts.get("WARNING", 0), 1)
        self.assertEqual(level_counts.get("ERROR", 0), 1)


class TestIntegrationScenarios(unittest.TestCase):
    """æµ‹è¯•é›†æˆåœºæ™¯"""
    
    def test_startup_with_dependency_issues(self):
        """æµ‹è¯•å¯åŠ¨æ—¶ä¾èµ–é—®é¢˜çš„å¤„ç†"""
        starter = IntelligentStarter()
        
        # æ¨¡æ‹Ÿä¾èµ–æ£€æŸ¥å¤±è´¥
        def mock_dependency_check():
            from src.utils.intelligent_starter import CheckResult, StartupPhase
            return CheckResult(
                phase=StartupPhase.DEPENDENCY_CHECK,
                success=False,
                message="ç¼ºå°‘ä¾èµ–åŒ…",
                details={"missing_packages": ["test-package"]},
                fix_available=True
            )
        
        starter.checkers[starter.checkers.__iter__().__next__()] = mock_dependency_check
        
        # æµ‹è¯•è‡ªåŠ¨ä¿®å¤
        with patch('subprocess.run') as mock_run:
            mock_run.return_value.returncode = 0
            
            starter.startup_config.enable_auto_fix = True
            result = starter._execute_startup_checks()
            
            # åœ¨å¯ç”¨è‡ªåŠ¨ä¿®å¤çš„æƒ…å†µä¸‹åº”è¯¥æˆåŠŸ
            self.assertTrue(result)
    
    def test_crash_recovery_workflow(self):
        """æµ‹è¯•å´©æºƒæ¢å¤å·¥ä½œæµ"""
        # æ¨¡æ‹Ÿå´©æºƒåœºæ™¯
        exception_center = get_exception_center()
        
        recovery_actions = []
        
        def mock_recovery(action_name, **kwargs):
            recovery_actions.append((action_name, kwargs))
            return True
        
        exception_center.execute_recovery = mock_recovery
        
        # è§¦å‘ä¸¥é‡å¼‚å¸¸
        critical_exception = RuntimeError("Critical system error")
        
        handled = exception_center.handle_exception(
            critical_exception, 
            severity=ExceptionSeverity.CRITICAL
        )
        
        # éªŒè¯å¼‚å¸¸è¢«è®°å½•
        stats = exception_center.get_exception_statistics()
        self.assertGreater(stats["total"], 0)
    
    def test_end_to_end_smart_start(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯æ™ºèƒ½å¯åŠ¨"""
        def mock_main_app():
            return True
        
        # æµ‹è¯•æˆåŠŸå¯åŠ¨åœºæ™¯
        with patch('src.utils.intelligent_starter.DependencyChecker') as mock_checker:
            mock_checker.return_value.check_all_dependencies.return_value = {
                "all_passed": True,
                "summary": "All dependencies OK"
            }
            
            with patch('src.utils.intelligent_starter.ConfigValidator') as mock_validator:
                mock_validator.return_value.validate_config.return_value = {
                    "valid": True,
                    "message": "Config is valid"
                }
                
                # æ‰§è¡Œæ™ºèƒ½å¯åŠ¨
                success = smart_start(mock_main_app, ["--mode", "normal"])
                self.assertTrue(success)


class TestPerformanceAndStability(unittest.TestCase):
    """æµ‹è¯•æ€§èƒ½å’Œç¨³å®šæ€§"""
    
    def test_exception_handler_performance(self):
        """æµ‹è¯•å¼‚å¸¸å¤„ç†å™¨æ€§èƒ½"""
        center = ExceptionHandlingCenter()
        
        # å¤§é‡å¼‚å¸¸å¤„ç†æµ‹è¯•
        start_time = time.time()
        
        for i in range(1000):
            try:
                raise ValueError(f"Test exception {i}")
            except ValueError as e:
                center.handle_exception(e)
        
        elapsed = time.time() - start_time
        
        # åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆæ¯”å¦‚5ç§’ï¼‰
        self.assertLess(elapsed, 5.0)
        
        # éªŒè¯æ‰€æœ‰å¼‚å¸¸éƒ½è¢«è®°å½•
        stats = center.get_exception_statistics()
        self.assertEqual(stats["total"], 1000)
    
    def test_concurrent_logging(self):
        """æµ‹è¯•å¹¶å‘æ—¥å¿—è®°å½•"""
        logger = setup_logger("ConcurrentTest")
        
        def log_worker(worker_id):
            for i in range(100):
                logger.info(f"Worker {worker_id} - Message {i}")
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for worker_id in range(10):
            thread = threading.Thread(target=log_worker, args=(worker_id,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # æµ‹è¯•å®Œæˆï¼Œæ²¡æœ‰å´©æºƒå°±æ˜¯æˆåŠŸ
        self.assertTrue(True)
    
    def test_memory_usage_stability(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨ç¨³å®šæ€§"""
        import gc
        
        # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
        gc.collect()
        initial_objects = len(gc.get_objects())
        
        # æ‰§è¡Œä¸€äº›æ“ä½œ
        for i in range(100):
            starter = IntelligentStarter()
            manager = AutoRepairManager()
            runner = DiagnosticRunner()
            
            # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
            starter.parse_arguments(["--mode", "normal"])
            problems = [
                Problem(ProblemType.CONFIG_INVALID, 5, f"Test problem {i}")
            ]
            manager.create_repair_plan(problems)
            
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        final_objects = len(gc.get_objects())
        
        # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        growth = final_objects - initial_objects
        self.assertLess(growth, 1000)  # å…è®¸å°‘é‡å¢é•¿


def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*60)
    
    # å¼‚å¸¸å¤„ç†æ€§èƒ½æµ‹è¯•
    print("\n1. å¼‚å¸¸å¤„ç†æ€§èƒ½æµ‹è¯•...")
    center = ExceptionHandlingCenter()
    
    start_time = time.time()
    for i in range(10000):
        try:
            if i % 3 == 0:
                raise ValueError("Test")
            elif i % 5 == 0:
                raise TypeError("Test")
            else:
                raise RuntimeError("Test")
        except Exception as e:
            center.handle_exception(e)
    
    elapsed = time.time() - start_time
    print(f"   å¤„ç†10000ä¸ªå¼‚å¸¸ç”¨æ—¶: {elapsed:.2f}ç§’")
    print(f"   å¹³å‡æ¯ç§’å¤„ç†: {10000/elapsed:.0f}ä¸ªå¼‚å¸¸")
    
    # æ™ºèƒ½å¯åŠ¨æ€§èƒ½æµ‹è¯•
    print("\n2. æ™ºèƒ½å¯åŠ¨æ€§èƒ½æµ‹è¯•...")
    starter = IntelligentStarter()
    
    start_time = time.time()
    for i in range(100):
        config = starter.parse_arguments(["--mode", "diagnostic", "--verbose"])
    elapsed = time.time() - start_time
    print(f"   100æ¬¡å‚æ•°è§£æç”¨æ—¶: {elapsed:.3f}ç§’")
    
    # è¯Šæ–­å·¥å…·æ€§èƒ½æµ‹è¯•
    print("\n3. è¯Šæ–­å·¥å…·æ€§èƒ½æµ‹è¯•...")
    runner = DiagnosticRunner()
    
    start_time = time.time()
    results = runner.run_all("json")
    elapsed = time.time() - start_time
    print(f"   å®Œæ•´è¯Šæ–­ç”¨æ—¶: {elapsed:.2f}ç§’")
    
    print("\nâœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ")


def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    print("=" * 60)
    print("ğŸ§ª Androidç³»ç»Ÿä¿®å¤å·¥å…·é—ªé€€é—®é¢˜ä¿®å¤ - ç»¼åˆæµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œå•å…ƒæµ‹è¯•
    print("\nğŸ“‹ è¿è¡Œå•å…ƒæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestExceptionHandlingCenter,
        TestIntelligentStarter,
        TestAutoRepairManager,
        TestDiagnosticTools,
        TestLoggerEnhancements,
        TestIntegrationScenarios,
        TestPerformanceAndStability
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"   - {test}: {traceback.split('AssertionError: ')[-1].strip()}")
    
    if result.errors:
        print(f"\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"   - {test}: {traceback.split('Exception: ')[-1].strip()}")
    
    # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
    if result.wasSuccessful():
        run_performance_benchmark()
    
    # è¿”å›ç»“æœ
    success = result.wasSuccessful()
    print(f"\n{'âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!' if success else 'âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥!'}")
    
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)